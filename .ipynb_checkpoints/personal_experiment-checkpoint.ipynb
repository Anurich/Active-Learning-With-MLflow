{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28748,
     "status": "ok",
     "timestamp": 1669810533184,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "ereEZ_GVfc42",
    "outputId": "0680a31b-bb40-441c-964c-366b22a75a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1669810758956,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "XRJ1QWRyfeNf",
    "outputId": "e669b308-1afc-4da3-b0bc-22ddbae4f39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/experimentationPersonal\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/experimentationPersonal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 20378,
     "status": "ok",
     "timestamp": 1669817352372,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "QCQV6qHhgSIO"
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip3 install transformers\n",
    "!pip3 install mlflow\n",
    "!pip install accelerate\n",
    "!pip3 install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRbcqLX3DA9T"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9cOGpqXDCHy"
   },
   "source": [
    "\n",
    "\n",
    "> **MLFlow CLI Command to run the preprocessing file.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33260,
     "status": "ok",
     "timestamp": 1669820329986,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "ZjTfF0sunbMl",
    "outputId": "f79afb1a-239d-455b-d662-e2a72745abe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 14:58:18 INFO mlflow.projects.utils: === Created directory /tmp/tmpx2fwgrvb for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/11/30 14:58:18 INFO mlflow.projects.backend.local: === Running command 'python preprocessing.py index2word.pickle word2index.pickle' in run with ID 'c2168f61135043dfbfec21d766a4ea23' === \n",
      "--------------------------------------- FOLD_0 ---------------------------------------\n",
      "--------------------------------------- FOLD_1 ---------------------------------------\n",
      "--------------------------------------- FOLD_2 ---------------------------------------\n",
      "--------------------------------------- FOLD_3 ---------------------------------------\n",
      "2022/11/30 14:58:49 INFO mlflow.projects: === Run (ID 'c2168f61135043dfbfec21d766a4ea23') succeeded ===\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell \n",
    "mlflow run --experiment-name prepData -b local \\\n",
    "--entry-point preprocessing_classification --env-manager local --run-name preprocessText \\\n",
    "-P index2word=\"index2word.pickle\" \\\n",
    "-P word2index=\"word2index.pickle\" \\\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaLGfEMbDLkM"
   },
   "source": [
    "> **MLFlow CLI Command to run the training file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 81437,
     "status": "error",
     "timestamp": 1669817307514,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "iliARvvSyf1f",
    "outputId": "4ad8f689-06d8-4328-d032-1880392ab234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 14:07:10 INFO mlflow.projects.utils: === Created directory /tmp/tmpgupc2xel for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/11/30 14:07:10 INFO mlflow.projects.backend.local: === Running command 'python train.py --grad_accumulation 1 --budget 200 --trainFile datasets/fold_0/train.csv --testFile datasets/fold_0/test.csv --batch 4 --lr 1e-5' in run with ID '5af6dc46238b4e69b40665edbe13be82' === \n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "############## Labelled Dataset: 200 && Unlabelled Dataset: 37300 ##############\n",
      "  4% 2/50 [00:58<23:17, 29.11s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 143, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 95, in main\n",
      "    output = model(**inputs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 1217, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 856, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 527, in forward\n",
      "    output_attentions,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 448, in forward\n",
      "    self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/pytorch_utils.py\", line 246, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 459, in feed_forward_chunk\n",
      "    intermediate_output = self.intermediate(attention_output)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 357, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "2022/11/30 14:08:20 ERROR mlflow.projects: === Run (ID '5af6dc46238b4e69b40665edbe13be82') interrupted, cancelling run ===\n",
      "\n",
      "Aborted!\n",
      "2022/11/30 14:08:22 INFO mlflow.projects.utils: === Created directory /tmp/tmpjvaaihu_ for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/11/30 14:08:22 INFO mlflow.projects.backend.local: === Running command 'python train.py --grad_accumulation 1 --budget 200 --trainFile datasets/fold_1/train.csv --testFile datasets/fold_1/test.csv --batch 4 --lr 1e-5' in run with ID 'fa578ebe540b46299b1eafbb9505a5c7' === \n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 5, in <module>\n",
      "    from customDataset import dataset\n",
      "  File \"/content/drive/MyDrive/experimentationPersonal/src/customDataset.py\", line 2, in <module>\n",
      "    from transformers import AutoTokenizer\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\", line 30, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/dependency_versions_check.py\", line 17, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/utils/__init__.py\", line 34, in <module>\n",
      "    from .generic import (\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/utils/generic.py\", line 33, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 51, in <module>\n",
      "    from ._api.v2 import compat\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/__init__.py\", line 37, in <module>\n",
      "    from . import v1\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
      "    from . import compat\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 37, in <module>\n",
      "    from . import v1\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2.compat.v1 import lite\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
      "    from . import experimental\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
      "    from . import authoring\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.lite.python.authoring.authoring import compatible\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/authoring/authoring.py\", line 43, in <module>\n",
      "    from tensorflow.lite.python import convert\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\", line 28, in <module>\n",
      "    from tensorflow.lite.python import util\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/util.py\", line 55, in <module>\n",
      "    from jax import xla_computation as _xla_computation\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/jax/__init__.py\", line 144, in <module>\n",
      "    from jax import debug as debug\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/jax/debug.py\", line 20, in <module>\n",
      "    from jax._src.debugger import breakpoint\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/debugger/__init__.py\", line 14, in <module>\n",
      "    from jax._src.debugger.core import breakpoint\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 857, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 525, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "2022/11/30 14:08:26 ERROR mlflow.projects: === Run (ID 'fa578ebe540b46299b1eafbb9505a5c7') interrupted, cancelling run ===\n",
      "\n",
      "Aborted!\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-81b991d94e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'for i in {0..4}\\ndo\\n  mlflow run --experiment-name TrainingModel -b local \\\\\\n  --entry-point training_classification --env-manager local --run-name fold_$i \\\\\\n  -P grad_accumulation=1 \\\\\\n  -P budget=200 \\\\\\n  -P trainFile=\"datasets/fold_$i/train.csv\" \\\\\\n  -P testFile=\"datasets/fold_$i/test.csv\" \\\\\\n  -P batch=4 \\\\\\n  -P lr=1e-5 \\\\\\n  src\\ndone\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 135\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'for i in {0..4}\ndo\n  mlflow run --experiment-name TrainingModel -b local \\\n  --entry-point training_classification --env-manager local --run-name fold_$i \\\n  -P grad_accumulation=1 \\\n  -P budget=200 \\\n  -P trainFile=\"datasets/fold_$i/train.csv\" \\\n  -P testFile=\"datasets/fold_$i/test.csv\" \\\n  -P batch=4 \\\n  -P lr=1e-5 \\\n  src\ndone\n' died with <Signals.SIGTERM: 15>."
     ]
    }
   ],
   "source": [
    "%%shell\n",
    "for i in {0..4}\n",
    "do\n",
    "  mlflow run --experiment-name TrainingModel -b local \\\n",
    "  --entry-point training_classification --env-manager local --run-name fold_$i \\\n",
    "  -P grad_accumulation=1 \\\n",
    "  -P budget=200 \\\n",
    "  -P trainFile=\"datasets/fold_$i/train.csv\" \\\n",
    "  -P testFile=\"datasets/fold_$i/test.csv\" \\\n",
    "  -P batch=4 \\\n",
    "  -P lr=1e-5 \\\n",
    "  src\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5372,
     "status": "ok",
     "timestamp": 1669818297119,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "h_9i82oK3VHQ",
    "outputId": "15f538ee-c71e-4409-b774-1383fb5464ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Token:··········\n",
      "MLflow Tracking UI: https://1eed-130-211-229-85.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "import mlflow\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "get_ipython().system_raw(\"mlflow ui --port 2000 &\")\n",
    "# Terminate open tunnels if exist\n",
    "ngrok.kill()\n",
    "\n",
    "# Setting the authtoken (optional)\n",
    "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
    "auth = getpass('Authentication Token:')\n",
    "ngrok.set_auth_token(auth)\n",
    "\n",
    "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
    "ngrok_tunnel = ngrok.connect(addr=\"2000\", proto=\"http\", bind_tls=True)\n",
    "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1669817475217,
     "user": {
      "displayName": "Anupam Nautiyal",
      "userId": "08497932859978403992"
     },
     "user_tz": -330
    },
    "id": "p0M7aXx34Fih",
    "outputId": "63ce797c-2097-4220-c473-81032be53b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrok: no process found\n"
     ]
    }
   ],
   "source": [
    "!killall ngrok"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPypcOLAk73GIq3Xm6pC66D",
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
